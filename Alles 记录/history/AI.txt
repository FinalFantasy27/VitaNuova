
https://mp.weixin.qq.com/s/jvVoRHWrMUx0T9YIaV8ZRQ

“Codex（利用Github上的代码训练得到的模型）训练不仅增强了模型在编程方面的能力，而且还带来了在多步推理上的显著提升。例如，在直接提出一个多步算术问题时，模型的准确率为17.7%。但当我们给模型加上引导性的语句，如：“Let’s think step by step”( 让我们一步一步思考)时，准确率会提升到惊人的78.7%。然而，如果加入误导性的信息，例如：“By using the fact that the earth is round”（运用‘地球是圆的’这个事实），准确率会降低到9.3%”

“在关于GPT3的论文中，有一张图详细描述了参数数量与上下文学习任务准确率之间的关系：
13亿参数：准确率约为5%；
130亿参数：准确率约为25%；
1750亿参数：准确率约为65%。
这显示了，即使模型的架构保持不变，只增加参数规模和训练数据，模型的性能也能得到显著的提升。这就是所谓的“缩放律”（Scaling Law）。伴随参数规模的增大，训练数据量也必须相应增加。例如，如果1750亿的参数仅使用40GB的训练数据，那效果可能会大打折扣。”

“OpenAI最近发布了一篇文章，使用GPT-4来解释GPT-2的工作原理，标题为《language models can explain neurons in language models》。GPT-2拥有大约30万个神经元。
Image
你可以选择任意一个神经元，系统将告诉你它的功能。我随意选择了第3层的第5个神经元，其输出结果是“positive adjectives and emotionally-charged words”（积极形容词和情感充沛的单词）。
例如，当输入如“great”、“fantastic”、“wonderful”、“amazing”和“tremendous”这样的积极形容词时，这个神经元会被激活。这个神经元的得分是0.56（总分为1），这个得分表示该神经元的解释有多可靠。
值得注意的是，当输入“innovation”（创新）这个词时，该神经元也被激活，但激活的程度较低。尽管“innovation”既不是形容词也不与情感相关，但文章中提到，有些功能可能需要多个神经元共同完成。
GPT-2中的30万神经元中，只有一千多个神经元的解释得分超过0.8，被认为是比较可靠的。它们包括关注“Canada”（加拿大）、“times”（时间）、“certainty”（确定性）和“success”（成功）的神经元。而大部分神经元的得分低于0.1。尽管这方面的研究仍处于初级阶段，但这样的尝试非常有意义。”

“最近，有研究指出，GPT4的（2023年）3月版本在素数识别任务上的准确率高达97%；但到了6月版本，其准确率骤降至2.4%。相比之下，ChatGPT在更新后表现反而有所提升，这显示出了语言模型的进化具有不稳定性。
这一现象可能与“向人类意图对齐”有关。存在一个所谓的“对齐税”现象，意味着过度追求意图对齐有时会导致模型表现下滑。”

2023.11.29
Scaling deep learning for materials discovery
https://www.nature.com/articles/s41586-023-06735-9
Deepmind号称新发现了220万种晶体材料